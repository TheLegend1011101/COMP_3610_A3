{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691dbc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "merged_df = pandas.read_csv(\"merged.csv\")\n",
    "\n",
    "user_review_counts = merged_df.groupby(\"user_id\").value_counts()\n",
    "\n",
    "valid_user_ids = user_review_counts[user_review_counts >= 5].index.get_level_values(0).unique()\n",
    "\n",
    "als_df = merged_df[merged_df[\"user_id\"].isin(valid_user_ids)]\n",
    "\n",
    "als_df = als_df[['user_id', 'asin', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91583ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = als_df['user_id'].unique().tolist()\n",
    "product_ids = als_df['asin'].unique().tolist()\n",
    "\n",
    "user_id_map = {user_id: i for i, user_id in enumerate(user_ids)}\n",
    "product_id_map = {product_id: i for i, product_id in enumerate(product_ids)}\n",
    "\n",
    "als_df['user_index'] = als_df['user_id'].map(user_id_map)\n",
    "als_df['product_index'] = als_df['asin'].map(product_id_map)\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = train_test_split(als_df[['user_index', 'product_index', 'rating']],\n",
    "                                                test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b25d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ALSExample\").getOrCreate()\n",
    "\n",
    "train_df_spark = spark.createDataFrame(train_data)\n",
    "test_df_spark = spark.createDataFrame(test_data)\n",
    "\n",
    "als = ALS(rank=10, maxIter=10, userCol=\"user_index\", itemCol=\"product_index\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "\n",
    "model = als.fit(train_df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a06086",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_df_spark)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"RMSE on the test set: {rmse}\")\n",
    "\n",
    "# Stop Spark Session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Code For Demonstrating Recommendations for Random Users in Test Set\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# # Re-initialize Spark Session if you stopped it earlier\n",
    "# spark = SparkSession.builder.appName(\"ALSRecommenderDemo\").getOrCreate()\n",
    "\n",
    "# # Convert your test_data (Pandas) to Spark DataFrame if needed\n",
    "# test_df_spark = spark.createDataFrame(test_data)\n",
    "\n",
    "# # Get a list of unique user indices from the test set\n",
    "# test_users = test_df_spark.select(\"user_index\").distinct().sample(fraction=0.1, seed=42).limit(3).collect()\n",
    "# test_user_indices = [row.user_index for row in test_users]\n",
    "\n",
    "# print(\"\\nTop 5 Recommendations for Random Users in Test Set:\")\n",
    "# for user_index in test_user_indices:\n",
    "#     user_recommendations = model.recommendForAllUsers(5) # Get top 5 for all users\n",
    "#     user_recs_df = user_recommendations.filter(user_recommendations.user_index == user_index) \\\n",
    "#                                        .select(\"recommendations\") \\\n",
    "#                                        .rdd.flatMap(lambda x: x).collect()[0]\n",
    "\n",
    "#     print(f\"\\nRecommendations for User Index: {user_index} (Original User ID: {user_ids[user_index]})\")\n",
    "#     for rec in user_recs_df:\n",
    "#         product_index = rec.product_index\n",
    "#         predicted_rating = rec.rating\n",
    "#         original_asin = product_ids[product_index]\n",
    "#         print(f\"  Product ASIN: {original_asin}, Predicted Rating: {predicted_rating:.2f}\")\n",
    "\n",
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
